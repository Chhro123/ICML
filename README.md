# PANDA: Phased Anomaly Diffusion with Progressive Mask Alignment for Anomaly Segmentation

## 📌 Introduction
**PANDA** (**Phased Anomaly Diffusion with Progressive Mask Alignment**) is a novel **anomaly synthesis framework** designed for **anomaly segmentation** tasks. It overcomes key limitations of existing Anomaly Synthesis (AS) methods by generating **high-fidelity, well-aligned, and fine-grained** synthetic anomalies, significantly enhancing anomaly segmentation performance.

### 🔹 Key Challenges in Anomaly Synthesis:
- **Lack of fine-grained texture** – Existing methods struggle to generate realistic anomaly textures.
- **Poor pixel alignment** – Many generative methods fail to properly align synthetic anomalies with the background.
- **Ignoring small anomalies** – Small, fine-grained anomalies are often overlooked during synthesis.

### ✅ How PANDA Solves These Problems:
1. **Phased Diffusion Sampling:** Injects real background information into the denoising process, ensuring realistic texture synthesis.
2. **Progressive Mask Alignment (PMA):** Smooths anomaly-background transitions, preventing misalignment artifacts.
3. **Dual-Branch Anomaly Synthesis:** Ensures small anomalies are effectively generated by integrating a dedicated **anomaly-only branch**.

PANDA achieves **state-of-the-art** (SOTA) performance on **MVTec-AD** and **BTAD** datasets, surpassing existing AS methods.

---

## 📄 Paper
If you find this work useful, please cite:

```bibtex
@inproceedings{PANDA2025,
  author = {Anonymous Authors},
  title = {PANDA: Phased Anomaly Diffusion with Progressive Mask Alignment for Anomaly Segmentation},
  booktitle = {International Conference on Machine Learning (ICML)},
  year = {2025}
}
```

---

## 🏗️ Repository Structure
```
├── assets/                 # Figures and visualizations
├── configs/                # Model configuration files
├── datasets/               # Data preprocessing scripts
├── models/                 # PANDA model implementation
├── scripts/                # Training and inference scripts
├── utils/                  # Utility functions
├── main.py                 # Entry point for training and testing
├── requirements.txt        # Required Python packages
├── README.md               # This file
```

---

## 📦 Installation
### 1️⃣ Clone the Repository
```bash
git clone https://github.com/your-repo/PANDA.git
cd PANDA
```

### 2️⃣ Install Dependencies
It is recommended to use a **virtual environment** (e.g., `venv` or `conda`).

```bash
pip install -r requirements.txt
```
OR (for Conda users)
```bash
conda create --name panda_env python=3.9
conda activate panda_env
pip install -r requirements.txt
```

### 3️⃣ Setup Datasets
Download and preprocess the datasets (MVTec-AD, BTAD):

```bash
bash scripts/download_datasets.sh
```

If you want to use your own dataset, place images in:
```
datasets/
├── my_dataset/
│   ├── train/  # Normal images
│   ├── test/   # Normal + Anomaly images
│   ├── masks/  # Ground truth anomaly masks
```

---

## 🚀 Training PANDA
To train PANDA on MVTec-AD:

```bash
python main.py --dataset mvtec --epochs 100 --batch_size 16
```
For BTAD dataset:
```bash
python main.py --dataset btad --epochs 100 --batch_size 16
```

✅ Training arguments:
| Argument        | Description                                   | Default |
|----------------|-----------------------------------------------|---------|
| `--dataset`    | Dataset name (`mvtec`, `btad`, `custom`)     | `mvtec` |
| `--epochs`     | Number of training epochs                    | `100`   |
| `--batch_size` | Batch size                                   | `16`    |
| `--lr`         | Learning rate                                | `1e-4`  |

---

## 🧐 Evaluation & Inference
Run inference on test images:

```bash
python main.py --mode test --dataset mvtec
```
OR for custom images:
```bash
python main.py --mode test --dataset custom --input_dir path/to/images
```

Results will be saved in `outputs/` directory.

---


## 📢 Acknowledgments
This work is built upon **Denoising Diffusion Models** and **Latent Diffusion Models (LDMs)**. We acknowledge contributions from prior work in **anomaly detection and segmentation**.

For questions or contributions, feel free to open an **Issue** or submit a **Pull Request**.

---

## 📜 License
This project is released under the **MIT License**.

---
